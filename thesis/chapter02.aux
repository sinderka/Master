\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{zerotransf}
\citation{energy}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Theory}{4}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Zero initial condition}{4}{section.2.1}}
\newlabel{sec:inittransf}{{2.1}{4}{Zero initial condition}{section.2.1}{}}
\newlabel{eqn:shiftedproblem}{{2.1}{4}{Zero initial condition}{equation.2.1.1}{}}
\citation{trapezoidal}
\citation{forwardeuler}
\citation{midpoint}
\citation{symplecticintegrator}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Energy}{5}{section.2.2}}
\newlabel{eqn:energy2}{{2.2}{5}{Energy}{equation.2.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Integration methods}{5}{section.2.3}}
\citation{expm}
\citation{expm}
\citation{convtrap}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Methods for integrating in time. Note that since the midpoint rule uses the midpoint $F_{i+\frac  {1}{2}}$, twice as many points needs to be saved for midpoint rule as for the other methods. Trapezoidal and midpoint rule have quadratic convergence rates, while forward Euler has linear convergence. To compare the methods it is therefore necessary to use the squared number of points for forward Euler as for the other methods. $g(t,u)$ is the right hand side of equation \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eqn:PDE}\unskip \@@italiccorr )}} or \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eqn:PDE1}\unskip \@@italiccorr )}}.\relax }}{6}{table.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:intmet}{{2.1}{6}{Methods for integrating in time. Note that since the midpoint rule uses the midpoint $F_{i+\frac {1}{2}}$, twice as many points needs to be saved for midpoint rule as for the other methods. Trapezoidal and midpoint rule have quadratic convergence rates, while forward Euler has linear convergence. To compare the methods it is therefore necessary to use the squared number of points for forward Euler as for the other methods. $g(t,u)$ is the right hand side of equation \eqref {eqn:PDE} or \eqref {eqn:PDE1}.\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Methods for exact integration in time. Since they are very computationally demanding they will only be used on small projected matrices. They also need the test problem to have constant energy. The expected convergence will be depending on the approximation of $A$, since this method is only exact in time. These function are explained in matlab's docmentation: \cite  {expm}. \relax }}{6}{table.caption.6}}
\newlabel{tab:intcorrect}{{2.2}{6}{Methods for exact integration in time. Since they are very computationally demanding they will only be used on small projected matrices. They also need the test problem to have constant energy. The expected convergence will be depending on the approximation of $A$, since this method is only exact in time. These function are explained in matlab's docmentation: \cite {expm}. \relax }{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Energy conservation for trapezoidal rule}{6}{subsection.2.3.1}}
\newlabel{eqn:energyconvinit}{{2.3}{6}{Energy conservation for trapezoidal rule}{equation.2.3.3}{}}
\citation{elenaperson}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Windowing}{7}{section.2.4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces  Windowing \relax }}{8}{algorithm.1}}
\newlabel{alg:Kversusk}{{1}{8}{Windowing \relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Solution methods}{8}{section.2.5}}
\newlabel{sec:solmet}{{2.5}{8}{Solution methods}{section.2.5}{}}
\newlabel{sec:KPM}{{2.5}{8}{Solution methods}{section.2.5}{}}
\citation{elena}
\citation{min}
\citation{kryprop}
\citation{arnold}
\citation{arnold}
\newlabel{eqn:PMform}{{2.4}{9}{Solution methods}{equation.2.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Arnoldi's Algorithm and the Krylov projection method}{9}{subsection.2.5.1}}
\newlabel{eqn:propA}{{2.5}{9}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Arnoldi's algorithm\cite  {arnold}\relax }}{10}{algorithm.2}}
\newlabel{alg:arnoldi}{{2}{10}{Arnoldi's algorithm\cite {arnold}\relax }{algorithm.2}{}}
\newlabel{eqn:KPMi}{{2.6}{10}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.6}{}}
\newlabel{eqn:Aresidual}{{2.7}{11}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.7}{}}
\newlabel{eqn:KPMdiff}{{2.8}{11}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.8}{}}
\newlabel{eqn:KPMr}{{2.9}{11}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.9}{}}
\citation{elenaconv}
\citation{SLMprop}
\citation{SLM}
\citation{SLMO}
\citation{SLM}
\citation{SLMO}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Symplectic Lanczos method}{12}{subsection.2.5.2}}
\newlabel{eqn:propS}{{2.10}{12}{Symplectic Lanczos method}{equation.2.5.10}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Symplectic Lanczos method \cite  {SLM}, with reortogonalization from \cite  {SLMO}. \relax }}{13}{algorithm.3}}
\newlabel{alg:symlanz}{{3}{13}{Symplectic Lanczos method \cite {SLM}, with reortogonalization from \cite {SLMO}. \relax }{algorithm.3}{}}
\citation{SLMconv}
\newlabel{eqn:SLMi}{{2.11}{14}{Symplectic Lanczos method}{equation.2.5.11}{}}
\newlabel{eqn:resenerg}{{2.12}{14}{Symplectic Lanczos method}{equation.2.5.12}{}}
\citation{SLMinteresting}
\citation{SLMpreserve}
\newlabel{eqn:SLMr}{{2.13}{15}{Symplectic Lanczos method}{equation.2.5.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{Proof that \texttt  {SLM} without restart is energy preserving}{15}{section*.7}}
\citation{linearerrorgrowth}
\@writefile{toc}{\contentsline {subsubsection}{Residual energy}{16}{section*.8}}
\newlabel{eqn:energy3}{{2.14}{16}{Residual energy}{equation.2.5.14}{}}
\newlabel{eqn:energy4}{{2.15}{16}{Residual energy}{equation.2.5.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}A comment on the orhogonalisation methods}{16}{subsection.2.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Direct method}{16}{subsection.2.5.4}}
\newlabel{sec:DM}{{2.5.4}{16}{Direct method}{subsection.2.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.5}Linearity of the methods}{17}{subsection.2.5.5}}
\citation{elena}
\citation{min}
\citation{waveequ}
\citation{min}
\citation{complex}
\citation{complex}
\newlabel{eqn:terrible}{{2.5.5}{18}{Linearity of the methods}{subsection.2.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.6}Number of operations}{18}{subsection.2.5.6}}
\citation{SLM1}
\citation{SLM2}
\citation{SLM3}
\citation{SLM4}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Computational cost of some mathematical operations. $n$ is restart variable, $\mathaccentV {hat}002{m}$ is the size of the full linear system, and $k$ is the number of steps in time. Computational costs are found in \cite  {complex}. \relax }}{19}{table.caption.9}}
\newlabel{tab:cd}{{2.3}{19}{Computational cost of some mathematical operations. $n$ is restart variable, $\hat {m}$ is the size of the full linear system, and $k$ is the number of steps in time. Computational costs are found in \cite {complex}. \relax }{table.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces  Number of operations needed for the different solving methods when trapezoidal rule is used. $i_r$ is the number of restarts needed for the methods to converge. For windowing $K\cdot k$ is equal to $k$ for the other methods. Windowing with \texttt  {DM} is not interesting since it is exactly the same method as \texttt  {DM}. \relax }}{19}{table.caption.10}}
\newlabel{tab:cc}{{2.4}{19}{Number of operations needed for the different solving methods when trapezoidal rule is used. $i_r$ is the number of restarts needed for the methods to converge. For windowing $K\cdot k$ is equal to $k$ for the other methods. Windowing with \texttt {DM} is not interesting since it is exactly the same method as \texttt {DM}. \relax }{table.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}\texttt  {SLM} and its eigenvalue solving properties}{19}{section.2.6}}
\citation{SLM4}
\@setckpt{chapter02}{
\setcounter{page}{21}
\setcounter{equation}{15}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{0}
\setcounter{table}{4}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{NAT@ctr}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{18}
\setcounter{ALC@unique}{44}
\setcounter{ALC@line}{23}
\setcounter{ALC@rem}{23}
\setcounter{ALC@depth}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{3}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{section@level}{1}
}
