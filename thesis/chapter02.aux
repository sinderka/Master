\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{zerotransf}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background theory}{4}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Zero initial condition}{4}{section.2.1}}
\newlabel{sec:inittransf}{{2.1}{4}{Zero initial condition}{section.2.1}{}}
\newlabel{eqn:shiftedproblem}{{2.1}{4}{Zero initial condition}{equation.2.1.1}{}}
\citation{energy}
\citation{trapezoidal}
\citation{forwardeuler}
\citation{midpoint}
\citation{symplecticintegrator}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Energy}{5}{section.2.2}}
\newlabel{eqn:energy2}{{2.2}{5}{Energy}{equation.2.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Integration methods}{5}{section.2.3}}
\citation{expm}
\citation{expm}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Methods for integrating in time. Note that since the midpoint rule uses the midpoint $F_{i+\frac  {1}{2}}$, twice as many points need to be saved for the midpoint rule than for the other methods. Trapezoidal and midpoint rule have quadratic convergence rates, while forward Euler has linear convergence. To compare the methods we use the squared number of points for forward Euler compared to the other methods. $g(t,u)$ is the right hand side of equation \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eqn:PDE}\unskip \@@italiccorr )}} or \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eqn:PDE1}\unskip \@@italiccorr )}}.\relax }}{6}{table.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:intmet}{{2.1}{6}{Methods for integrating in time. Note that since the midpoint rule uses the midpoint $F_{i+\frac {1}{2}}$, twice as many points need to be saved for the midpoint rule than for the other methods. Trapezoidal and midpoint rule have quadratic convergence rates, while forward Euler has linear convergence. To compare the methods we use the squared number of points for forward Euler compared to the other methods. $g(t,u)$ is the right hand side of equation \eqref {eqn:PDE} or \eqref {eqn:PDE1}.\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Methods for exact integration in time. Since they are very computationally demanding they will only be used on small projected matrices. They also need the test problem to have constant energy. The expected convergence will be depending on the approximation of $A$, since this method is only exact in time. These build in function are explained in MATLAB's docmentation: \cite  {expm}. \relax }}{6}{table.caption.6}}
\newlabel{tab:intcorrect}{{2.2}{6}{Methods for exact integration in time. Since they are very computationally demanding they will only be used on small projected matrices. They also need the test problem to have constant energy. The expected convergence will be depending on the approximation of $A$, since this method is only exact in time. These build in function are explained in MATLAB's docmentation: \cite {expm}. \relax }{table.caption.6}{}}
\citation{convtrap}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Energy conservation for the trapezoidal rule}{7}{subsection.2.3.1}}
\newlabel{eqn:energyconvinit}{{2.4}{7}{Energy conservation for the trapezoidal rule}{equation.2.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Windowing}{8}{section.2.4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces  Windowing \relax }}{8}{algorithm.1}}
\newlabel{alg:Kversusk}{{1}{8}{Windowing \relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Solution methods}{8}{section.2.5}}
\newlabel{sec:solmet}{{2.5}{8}{Solution methods}{section.2.5}{}}
\newlabel{sec:KPM}{{2.5}{8}{Solution methods}{section.2.5}{}}
\citation{elena}
\citation{min}
\citation{kryprop}
\citation{arnold}
\citation{arnold}
\newlabel{eqn:PMform}{{2.5}{9}{Solution methods}{equation.2.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Arnoldi's Algorithm and the Krylov projection method}{9}{subsection.2.5.1}}
\newlabel{eqn:propA}{{2.6}{9}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.6}{}}
\newlabel{eqn:stuff}{{2.7}{9}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.7}{}}
\citation{arnoldconv}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Arnoldi's algorithm\cite  {arnold}\relax }}{10}{algorithm.2}}
\newlabel{alg:arnoldi}{{2}{10}{Arnoldi's algorithm\cite {arnold}\relax }{algorithm.2}{}}
\newlabel{eqn:Aresidual}{{2.8}{10}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.8}{}}
\citation{elenaconv}
\newlabel{eqn:KPMdiff}{{2.9}{11}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.9}{}}
\newlabel{eqn:KPMr}{{2.10}{11}{Arnoldi's Algorithm and the Krylov projection method}{equation.2.5.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Symplectic Lanczos method}{11}{subsection.2.5.2}}
\citation{SLM}
\citation{SLMO}
\citation{SLM}
\citation{SLMO}
\newlabel{eqn:propS}{{2.11}{12}{Symplectic Lanczos method}{equation.2.5.11}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Symplectic Lanczos method \cite  {SLM}, with reortogonalization from \cite  {SLMO}. \relax }}{12}{algorithm.3}}
\newlabel{alg:symlanz}{{3}{12}{Symplectic Lanczos method \cite {SLM}, with reortogonalization from \cite {SLMO}. \relax }{algorithm.3}{}}
\citation{SLMconv}
\newlabel{eqn:SLMi}{{2.12}{13}{Symplectic Lanczos method}{equation.2.5.12}{}}
\citation{SLMinteresting}
\citation{SLMpreserve}
\newlabel{eqn:SLMr}{{2.13}{14}{Symplectic Lanczos method}{equation.2.5.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{Proof that \texttt  {SLM} without restart is energy preserving}{14}{section*.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Linearity of the methods}{15}{subsection.2.5.3}}
\citation{elena}
\citation{min}
\citation{waveequ}
\citation{min}
\newlabel{eqn:terrible}{{2.14}{16}{Linearity of the methods}{equation.2.5.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}A comment on the restart}{16}{subsection.2.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.5}Direct method}{16}{subsection.2.5.5}}
\newlabel{sec:DM}{{2.5.5}{16}{Direct method}{subsection.2.5.5}{}}
\citation{linearerrorgrowth}
\citation{complex}
\citation{complex}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.6}Number of operations}{17}{subsection.2.5.6}}
\citation{SLM1}
\citation{SLM2}
\citation{SLM4}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Computational cost of some mathematical operations. $n$ is restart variable, $\mathaccentV {hat}002{m}$ is the size of the full linear system, and $k$ is the number of steps in time. Computational costs are found in \cite  {complex}. \relax }}{18}{table.caption.8}}
\newlabel{tab:cd}{{2.3}{18}{Computational cost of some mathematical operations. $n$ is restart variable, $\hat {m}$ is the size of the full linear system, and $k$ is the number of steps in time. Computational costs are found in \cite {complex}. \relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces  Number of operations needed for the different solving methods when trapezoidal rule is used. $i_r$ is the number of restarts needed for the methods to converge. For windowing $K\cdot k$ is equal to $k$ for the other methods. Windowing with \texttt  {DM} is not interesting since it is exactly the same method as \texttt  {DM}. \relax }}{18}{table.caption.9}}
\newlabel{tab:cc}{{2.4}{18}{Number of operations needed for the different solving methods when trapezoidal rule is used. $i_r$ is the number of restarts needed for the methods to converge. For windowing $K\cdot k$ is equal to $k$ for the other methods. Windowing with \texttt {DM} is not interesting since it is exactly the same method as \texttt {DM}. \relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}\texttt  {SLM} and its eigenvalue solving properties}{18}{section.2.6}}
\@setckpt{chapter02}{
\setcounter{page}{20}
\setcounter{equation}{14}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{0}
\setcounter{table}{4}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{NAT@ctr}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{18}
\setcounter{ALC@unique}{45}
\setcounter{ALC@line}{24}
\setcounter{ALC@rem}{24}
\setcounter{ALC@depth}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{3}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{section@level}{1}
}
