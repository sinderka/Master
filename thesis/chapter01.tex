%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Skrive litt om problemet, layouten og slikt. \\
!!!!!!!!!!!!!!!!!!!!!!cite rapport og SLM !!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Cite hamiltonian!!!!!!!!!!!!!!!!!!!!\\
The equation 
\begin{equation} 
\begin{aligned}
\dot{u}(t) &= A u(t) + F(t) \\
u(0)&= u_0
\end{aligned}
\label{eqn:PDE}
\end{equation}
often makes an appearance when solving partial differential equations with numerical methods. The author has earlier observed how the heat equation, discretized with finite difference methods to be on the form of equation \eqref{eqn:PDE} can be solved with the use of the Krylov projection method(KPM) \cite{min}. This note will continue on the same track, with more focus on the wave equation, and energy preservation. It will also feature a comparison between Symplectic Lanzcos method(SLM) \cite{SLM} and KPM. SLM is a projection technique that only works on Hamiltonian matrices. Due to this, SLM (claim to) preserve energy better than KPM.\\

!!!!!!!!!!!!!!!!!!!MÅ cite forsjkellig når jeg vil/anbefaler å lese hele, og når jeg anbefaler å lese deler av det!!!!!!!!!\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Explonation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
!!!!!!!!!!!!!!!!!Alt må leses igjennom!!!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!!Citinger må fikses!!!!!!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!Bilder må oppdateres!!!!!!!!!!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!!!!!Det må skrives en del tekts mange steder!!!!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!og bedre forklaringer mange steder!!!!!!!!!!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!mye å ta tak i med andre ord!!!!!!!!!!!!!!!!\\
There will here be a short explanation of all solvers, constants, outdata and expressions used in this text. Matlab notation is used where applicable. Fell free to go straight to next chapter, and use this as a reference later in the note.

\section{Projection methods}
As mentioned earlier, two projection methods will be presented, KPM and SLM. They are very similar in nature, with the only difference being the orthogonalisation method. KPM uses Arnoldi's algorithm, given in Algorithm \ref{alg:arnoldi}, and SLM uses the symplectic Lanczos method, given in Algorithm \ref{alg:symlanz}. The framework is given in Algorithm \ref{alg:PM}. \\
!!!!!!!!!!!!!!!!!Må forklare mer hva som er foskejllen på $m$ og $2m$!!!!!!!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!!!forklare bedre hva $n$ er, og slikt!!!!!!!!!!!!!!!!!!!!!\\
\begin{algorithm} 
\begin{algorithmic} \caption{Arnoldi's algorithm\cite{arnold}} \label{alg:arnoldi}  
\STATE Start with $A \in \mathbb{R}^{m \times m}$, $v \in \mathbb{R}^{m}$, $n \in \mathbb{N}$ and $\epsilon \in \mathbb{R}$.
\STATE $v_1 = v/\|v \|_2$
\FOR{$j = 1,2,\cdots, n $} 
   \STATE Compute $h_{i,j} =  v_iAv_j,v_i $ for $i = 1,2,\cdots, j$
    \STATE Compute $w_j = A v_j - \Sigma_{i=1}^{j} h_{i,j}v_i $
    \STATE $h_{j+1,j} = \| w_j \|_2$
    \IF{$h_{j+1,j} < \epsilon $} 
        \STATE\textbf{STOP}
    \ENDIF 
   \STATE $v_{j+1} = w_j/h_{j+1,j}$
\ENDFOR
\STATE Return $H$, $V$, $v_{n+1}$, $h_{n+1,n}$.
\end{algorithmic} 
\end{algorithm}

\begin{algorithm} \caption{Symplectic Lanczos method \cite{SLM}, with reortogonalization from \cite{SLMO}. } \label{alg:symlanz}
\begin{algorithmic}
\STATE Start with a Hamiltonian matrix $A \in \mathbb{R}^{2m \times 2m}$, $\tilde{v_1} \in \mathbb{R}^{2m}$, $n \in \mathbb{N}$
\STATE $v_0= 0 \in \mathbb{R}^{2m}$
\STATE $\xi_1 = \| \tilde{v}_1\|_2$
\STATE $v_1= \frac{1}{\xi_1}  \tilde{v}_1$
\FOR {$j = 1,2, \cdots, n$}
	\STATE $v = A v_j$
	\STATE $\delta_j =  v_j^\top$
	\STATE $\tilde{w} = v-\delta_j v_j$
	\STATE $\kappa_j = v_j^\top J v $
	\STATE $w_j = \frac{1}{\kappa_j} \tilde{w_j}$
	\STATE $w = A w^j$
	\STATE $ \tilde{V}_{j-1} = [v_1,v_2,\cdots,v_{j-1},w_1,w_2,\cdots,w_{j-1}] $
	\STATE $ w_j = w_j + \tilde{V}_{j-1}J_{j-1} \tilde{V}_{j-1}^\top J^m w_j $
	\STATE $\beta = -w_j^\top J w$
	\STATE $\tilde{v}_{j+1} = w - \xi_j v_{j-1} - \beta_j v_j + \delta_j v_j$
	\STATE $ \xi_{j+1} = \|\tilde{v}_{j+1} \|_2 $
	\STATE $ v_{j+1} = \frac{1}{\xi_{j+1}} \tilde{v}_{j+1} $
	\STATE $ \tilde{V}_j = [v_1,v_2,\cdots,v_{j},w_1,w_2,\cdots,w_{j}] $
	\STATE $ v_{j+1} = v_{j+1} + \tilde{V}_j J_j \tilde{V}_j^\top J_m v_{j+1} $
\ENDFOR
\STATE $V = [v_1,v_2,\cdots,v_n,w_1,w_2,\cdots,w_n]$
\STATE $H = \begin{bmatrix}
\text{diag} \big( [\delta_j]^n_{j=1} \big) & \text{tridiag}\big( [\xi]_{j=2}^n,[\beta]_{j=1}^n,[\xi]_{j=2}^n \big)
\end{bmatrix} $
\STATE Return $H$, $V$, $v_{n+1}$, $\xi_{n+1}$.
\end{algorithmic}
\end{algorithm}
Note that $n$ given to Algorithm \ref{alg:symlanz} is half the size of $n$ given to Algorithm \ref{alg:arnoldi}, due to the way the orthogonalisation is done.

\begin{algorithm}
\begin{algorithmic} \caption{The Krylov projection method with restart\cite{min}} \label{alg:PM} 
\STATE Start with $A \in \mathbb{R}^{m \times m}$, $f(t)$, $v \in \mathbb{R}^{m}$, $n \in \mathbb{N}$, a boolean value \texttt{restart}, an algorithm \texttt{alg}, $\epsilon \in \mathbb{R}$, and $i = 0$.
\STATE Compute $[V_n,H_n,h_{n+1,n}^i,v_{n+1}] = \texttt{alg}(A,v,n)$
\STATE Solve $  z_i'(t) = H_n z_i(t) + f(t) \| v \|_2 e_1  $ for $z_i(t)$
\STATE $ u_n(t) \leftarrow  V_n z_i(t) $
\STATE $ \delta = h_{n+1,n} $ 
\IF { \texttt{restart} == 1 }
	\WHILE{ $\epsilon < \delta$  } 
    		\STATE $i \leftarrow i + 1$
    		\STATE Compute $[V_n,H_n,h_{n+1,n}^i,v_{n+1}] = \texttt{alg}(A,v_{n+1},n)$
    		\STATE Solve $ z_i'(t) = H_n z_i(t) + h_{n+1,n}^{i-1}e_n^\top z_{i-1}(t)  $ for $z_i(t)$
    		\STATE $ u_n(t) \leftarrow u_n(t) + V_n z_i(t) $
    		\STATE $\delta = \max(u_n(t) - V_n z_i(t))$
	\ENDWHILE
\ENDIF
\STATE Return $u_n$.
\end{algorithmic} 
\end{algorithm}

The approximated solution, found by either SLM or KPM, will be denoted as $u_n$, where $n$ the same as above. \\

If the solution is obtained without the use of an orthogonalisation, it will be denoted with DM for direct method.


\section{Zero initial condition}
For both KPM and SLM it is important that the initial conditions are zero. Equation \eqref{eqn:PDE} can be transformed so that it has zero initial conditions in the following way:
\begin{equation*}
\hat{u}(t) = u(t)-u_0
\end{equation*}
The original equation can then be written as
\begin{equation}
\begin{aligned}
\hat{\dot{u}}(t) &= A \hat{u}(t) +A u_0 + F(t) \\
 \hat{u}(0)&= 0 \\
 u(t) = \hat{u} + u_0 \\
\end{aligned}.
\end{equation}

All test problems with a non-zero initial condition will be transformed in this way.

\section{Discretization}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%!!!!!!!!!!!!!!!!!!!!!!!!!!$J$ må defineres et sted!!!!!!!!!!!!!!!!!!!!!!!!!!!\\
%!!!!!!!!!!!!!!!!!!!!!!!!!sAMMEN MED $I$!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!alle steder med $y$ må endres til $u$!!!!!!!!!!!!!!!!!!!!!!!\\
%!!!!!!!!!!!!!!!!!!!!!!!!!!!må jeg cite, eller definere hamilton?!!!!!!!!!!!!!!!!!!!!!!!!!\\
%!!!!!!!!!!!!!!!!!!!!!!!Skrive hvorfor random matrisa er diagonal dominant !!!!!!!!!!!!!!!!!!!!\\
%!!!!!!!!!!!!!!!!!!!!!Skrive at random matrise er et tilfeldig 2 dimensjonalt system!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!Figurer over simulert tid må være med ekte simulert tid fra 0 til 1(tror dette er fikset!, trenger bare nye bilder)!!!!!!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!!!Mange av bildene skal ha $k$ og ikke time på x-aksen(tror dette er fikset, trenger bare nye bilder)!!!!!!!!!!!!!!!!!!!!!!!!!\\
%!!!!!!!!!!!!!!!!!!må bruke eqref isteden for ref noen steder!!!!!!!!!!!!!!!!!!!!!!!!!!!\\
%!!!!!!!!!!!!!!!!!Dirmet må også forklares!!!!!!!!!!!!!!!!!!!!!!!!!\\
%!!!!!!!!!!!!!!!!!!!må forklare hva u_n er!!!!!!!!!!!!!!!!!!!!\\

The number of points in each spacial direction is $m$, this gives makes the step size $h_s = 1/m$. The number of steps in time is $k$, this makes the step size $h_t = 1/k$.\\

Let the matrix $I$ be the identity matrix of appropriate size, and let 
\begin{equation}
J = 
\begin{bmatrix}
0&I\\-I&0
\end{bmatrix}
\end{equation}
of appropriate size.\\

Equation \eqref{eqn:PDE} can be the result of the discretization of several equation. Since SLM needs a Hamiltonian matrix, this is the main focus. One of the two implemented matrices is the discretization of the 2 dimensional wave equation, 
\begin{equation}
\begin{aligned}
\frac{\partial^2 u}{\partial t^2} = \frac{\partial^2 u}{\partial x^2}+ \frac{\partial^2 u}{\partial y^2} + f(t,x,y).
\end{aligned}
\label{eqn:wave}
\end{equation}
This can be discretized to be on the form of equation \eqref{eqn:PDE}, with the matrix
\begin{equation}
\begin{aligned}
\tilde{A} &= \frac{2}{h_s^2} \text{ gallery}('\text{poisson}', m-2) \\
A &= 
\begin{bmatrix}
 0 & I \\ - \tilde{A} & 0 \\
\end{bmatrix}
\end{aligned}.
\end{equation}
The matrix $\tilde{A}$ is also known as the five-point stencil. This matrix will be referred to as \texttt{wave} when used. The second implemented matrix is a random Hamiltonian matrix, given by
\begin{equation}
\hat{A} = \text{rand}(2 (m-2)^2) \\
A = \frac{1}{2} J (\hat{A} + \hat{A}^\top + m^2 I).
\end{equation}
Since we are interested in comparing the different projection methods to each other, the matrix will be saved and reused when necessary. This matrix will be referred to as \texttt{semirandom}. The part $m^2 I $ is added to make $JA$ diagonally dominant, there would be no way of knowing if any of the methods would converge without this part.% The matrix is simulated to be a 2 dimensional system. 

These two matrices also has some test problems that satisfies the condition: $u(t,0,y) = u(t,1,y) = u(t,x,0) = u(t,x,1) = 0$. \\

In the case when the energy is constant and \texttt{wave} is used, the test problem is 
\begin{equation}
\begin{aligned}
u(t,x,y) &= \sin(\pi x) \sin(\pi y) \cos(\sqrt{2} \pi t) \\
u_0 &= \sin( \pi x) \sin(\pi y) \\
f(t,x,y) &= 0 ,
\end{aligned}
\end{equation}
and 
\begin{equation}
\begin{aligned}
u(t,x,y) &= \text{unknown} \\
u_0 &= \text{rand} (2 (m-2)^2,1) \\
f(t,x,y) &= 0
\end{aligned}
\end{equation}
for \texttt{semirandom}. This test problem is kept with the same conditions as $A$.

The source term $f(t,x,y)$ is chosen to be zero because it is easier to work with a constant energy. Some problems with non-constant energy will be presented later.


\section{Lingo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
!!!!!!!!!!!!!!!!!!!!!Skriv noe her!!!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!!!!!!Forklare forskjellen på $u$ og $U$?!!!!!!!!!!!!!!!!\\
There will here be a short explanation of the labels on the figures you will see later. 
\begin{table}[h]
\centering
\begin{tabular}{l|l}
 iterations& number of restarts performed by Arnoldi or symplectic Lanczos method.  \\
 time & computation time elapsed when solving the problem \\
 error1 &  Difference in error between analytical solution, and estimated solution. \\
 energy1 & Difference between the largest and smallest energy during the simulated time. \\
% error2 & Difference in error between orthogonalised solution, and the\\& non-orthogonalised solution. \\
% energy2 &Difference in energy between orthogonalised solution, and the\\& non-orthogonalised solution. \\
\end{tabular}
\caption{ Explanation of the labels on the y-axis. }
\label{tab:ylabels}
\end{table}

!!!!!!!!!!!!!!!!!!!!!Skriv noe her!!!!!!!!!!!!!!!!\\
!!!!!!!!!!!!!!!!!!!!!!!Lag en bedre tabell!!!!!!!!!!!!!!!!\\

\begin{table}[h]
\centering
\begin{tabular}{l l}
$m$ & number of point in each spacial direction \\
$n$ & size of orthogonal space \\
$k$ & number of points in time \\
$t$ & simulated time \\
\texttt{restart}& a boolean value. If \texttt{restart} == 1, Arnoldi or \\&symplectic Lanczos method will restart. \\
$\epsilon$ & if \texttt{restart} is true, restarting will\\& commence until the change in the solution\\& is less than $\epsilon$ \\
\end{tabular}
\caption{ Explanation of the labels on the x-axis. }
\label{tab:xlabels}
\end{table}

!!!!!!!!!!!!!!!!!!!Fyll inn etterhvert som du trenger det!!!!!!!!!!!!!!!!!!!!\\